{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae9b5ff4-d8fb-4267-ae34-814ea15d4bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext, Settings\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, PodSpec\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "401fb397-2a57-4785-9443-dc49799104d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext, Settings\n",
    "# from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "# from pinecone import Pinecone, PodSpec\n",
    "# from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "# import nest_asyncio\n",
    "\n",
    "# from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "# Settings.embed_model = GeminiEmbedding(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6034c069-0bfb-4136-8716-2d29164527f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b904a29-3b95-4ec1-894d-6132d8ff15e4",
   "metadata": {},
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b36594c0-7586-4a93-a511-3cd86942e767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "# Load the file manually since it's .txt\n",
    "config = dotenv_values(\"dotenv.txt\")\n",
    "\n",
    "# Access keys\n",
    "pinecone_api_key = config[\"PINECONE_API_KEY\"]\n",
    "pinecone_env = config[\"PINECONE_ENVIRONMENT\"]\n",
    "pinecone_index_name = config[\"PINECONE_INDEX\"]\n",
    "gemini_api_key = config[\"GEMINI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3761ef8a-48cc-4944-ada5-0edfe1703e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openai google-generativeai pinecone-client python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a91902c-8af8-418a-a954-cf3bded271b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb9a75ea-4145-46c9-9010-28e98513113a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.pinecone.Pinecone at 0x73c22fe64f10>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e0d27b4-1ac9-4fb5-ab1a-4ad771327e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document(s).\n"
     ]
    }
   ],
   "source": [
    "# Load the PDF Document\n",
    "pdf_path = \"/home/mohankalyan/Downloads/KosaraMohanKalyanResume-1.pdf\"\n",
    "\n",
    "# Example for Windows (note the 'r' before the string)\n",
    "# pdf_path = r\"C:\\Users\\yourusername\\Downloads\\attention-is-all-you-need.pdf\"\n",
    "\n",
    "try:\n",
    "    documents = SimpleDirectoryReader(input_files=[pdf_path]).load_data()\n",
    "    print(f\"Loaded {len(documents)} document(s).\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading the PDF file: {e}\")\n",
    "    print(f\"Please check that the path is correct: {pdf_path}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e896622-783b-4f55-8546-33e7df327b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"chatbot\"\n",
    "pinecone_environment = \"us-east-1-aws\" # Or your actual environment\n",
    "embedding_dimension = 768 # Dimension of the 'all-MiniLM-L6-v2' model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c251bb83-f0ce-4daa-8628-49c0a26058c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinecone index 'chatbot' already exists.\n"
     ]
    }
   ],
   "source": [
    "if index_name not in pc.list_indexes().names():\n",
    "    print(f\"Creating Pinecone index: {index_name}\")\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=embedding_dimension,\n",
    "        metric=\"cosine\",\n",
    "        spec=PodSpec(environment=pinecone_environment)\n",
    "    )\n",
    "    print(\"Index created successfully.\")\n",
    "else:\n",
    "    print(f\"Pinecone index '{index_name}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba081783-b497-4f83-92e5-15a56d9552e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_index = pc.Index(index_name)\n",
    "vector_store = PineconeVectorStore(pinecone_index=pinecone_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e14d9847-2b26-4da8-9cfb-afec557591bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "# Apply the patch\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f915889b-7f3a-48e4-8392-07f723214186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index and storing embeddings in Pinecone... This may take a moment.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a272fa4d4de449519c5b40f87b785fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished indexing and storing.\n"
     ]
    }
   ],
   "source": [
    "# --- 8. Create the Index ---\n",
    "print(\"Creating index and storing embeddings in Pinecone... This may take a moment.\")\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    ")\n",
    "print(\"Finished indexing and storing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "161cc381-0142-4790-b6a4-b0acc3d68b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6767/1051181578.py:5: DeprecationWarning: Call to deprecated class Gemini. (Should use `llama-index-llms-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/llm/google_genai/)\n",
      "  llm = Gemini(\n",
      "/tmp/ipykernel_6767/1051181578.py:10: DeprecationWarning: Call to deprecated class GeminiEmbedding. (Should use `llama-index-embeddings-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/embeddings/google_genai/)\n",
      "  embed_model = GeminiEmbedding(\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Setup LlamaIndex Components (Same as before)\n",
    "from llama_index.core import Settings, Document\n",
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "from llama_index.llms.gemini import Gemini\n",
    "llm = Gemini(\n",
    "        model=\"models/gemini-1.5-flash\",\n",
    "        api_key=GOOGLE_API_KEY\n",
    "    )\n",
    "    \n",
    "embed_model = GeminiEmbedding(\n",
    "        model_name=\"models/embedding-001\",\n",
    "        api_key=GOOGLE_API_KEY\n",
    "    )\n",
    "    \n",
    "    # Configure global settings\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.chunk_size = 500  # Good for PDF text\n",
    "Settings.chunk_overlap = 200  # More overlap for PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ea7475a-a017-4e14-8f85-b5e2edb1bd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This document is a resume for Kosara Mohan Kalyan, highlighting their skills, education, projects, and experience in software development and machine learning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "\n",
    "response = query_engine.query(\"What is this document about?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cffdf95f-1915-4cdd-a976-605ddd4b6c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask a question:  skills\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The individual possesses skills in C, Python, Java, HTML, CSS, machine learning, and MySQL.  They also have experience with data structures using C.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask a question:  exit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    q = input(\"Ask a question: \")\n",
    "    if q.lower() in [\"exit\", \"quit\"]: break\n",
    "    print(query_engine.query(q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c5d805-e844-4009-b4ad-cf84b103eede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9641dbc-bb92-4c99-b2f3-8af5db75fd64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8c62aa-a183-4d82-b68f-9477bd9c9f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8c89b8-2c2d-4136-ba46-a6fa9fb6fd24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503e603f-faf8-4808-a585-37a747847f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b91e7d-c985-401f-9cc1-ddab3f15e901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132dd019-9577-4869-bf76-c803d8f7f25a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
